---
title: Porting Flask to FastAPI for ML Model Serving
layout: post_norel
permalink: /pages/projects/flask-to-fastapi
---

tl;dr [read more here](https://www.pluralsight.com/tech-blog/porting-flask-to-fastapi-for-ml-model-serving/!)

Flask is fairly ubiquitous for building minimal webservices in Python, particularly for serving ML models behind REST APIs (like in [my previous post](/pages/projects/model-serving)) where simplicity and flexibility are more desirable than the "batteries included" all-in-one approach used by frameworks like Django.
More recently (that is, in Python 3.4+) there have been significant changes to Python's type annotation behavior and asynchronous interface, as well as new developments in underlying tools (like natively asynchronous ASGI webservers) that open up opportunities for more modern frameworks.

[FastAPI](https://fastapi.tiangolo.com/) takes advantage of these developments to deliver robust, responsive, and readable web APIs, with performance on par with the best Node.js or Go can offer - and since, by design, FastAPI coding looks a _lot_ like Flask, porting REST APIs from Flask to FastAPI isn't too daunting a task.
I recently published a walkthrough on porting a Flask API serving a simple machine learning model to FastAPI through Pluralsight's tech blog, available [in this post](https://www.pluralsight.com/tech-blog/porting-flask-to-fastapi-for-ml-model-serving/).
Example code is available on Github [here](https://github.com/pluralsight/tech-blog-fastapi-demo), including a fully Dockerized implementation plus an example config for production-ready deployment with `gunicorn`.
Enjoy!
